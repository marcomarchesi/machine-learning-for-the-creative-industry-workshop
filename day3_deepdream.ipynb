{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of day3_deepdream.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6whFltoD09fT","colab_type":"text"},"source":["# Some import"]},{"cell_type":"code","metadata":{"id":"21kFZ8CL0849","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torchvision import models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import argparse\n","import os\n","import tqdm\n","import scipy.ndimage as nd\n","from torchvision import transforms"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vax8V9nr1S1P","colab_type":"text"},"source":["# Processing images"]},{"cell_type":"code","metadata":{"id":"NgxAn5yh00WM","colab_type":"code","colab":{}},"source":["mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])\n","\n","preprocess = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n","\n","\n","def deprocess(image_np):\n","    image_np = image_np.squeeze().transpose(1, 2, 0)\n","    image_np = image_np * std.reshape((1, 1, 3)) + mean.reshape((1, 1, 3))\n","    image_np = np.clip(image_np, 0.0, 255.0)\n","    return image_np\n","\n","\n","def clip(image_tensor):\n","    for c in range(3):\n","        m, s = mean[c], std[c]\n","        image_tensor[0, c] = torch.clamp(image_tensor[0, c], -m / s, (1 - m) / s)\n","    return image_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iT5nV50p1gq3","colab_type":"text"},"source":["# Create the allucination\n"]},{"cell_type":"code","metadata":{"id":"cCPSSnUd1joL","colab_type":"code","colab":{}},"source":["def dream(image, model, iterations, lr):\n","    \"\"\" Updates the image to maximize outputs for n iterations \"\"\"\n","    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available else torch.FloatTensor\n","    image = Variable(Tensor(image), requires_grad=True)\n","    for i in range(iterations):\n","        model.zero_grad()\n","        out = model(image)\n","        loss = out.norm()\n","        loss.backward()\n","        avg_grad = np.abs(image.grad.data.cpu().numpy()).mean()\n","        norm_lr = lr / avg_grad\n","        image.data += norm_lr * image.grad.data\n","        image.data = clip(image.data)\n","        image.grad.data.zero_()\n","    return image.cpu().data.numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t6ikJNaD1o5a","colab_type":"text"},"source":["# Main method\n"]},{"cell_type":"code","metadata":{"id":"ZV_rowPP1q-Y","colab_type":"code","colab":{}},"source":["def deep_dream(image, model, iterations, lr, octave_scale, num_octaves):\n","    # deep dream method\n","    image = preprocess(image).unsqueeze(0).cpu().data.numpy()\n","\n","    # Extract image representations for each octave\n","    octaves = [image]\n","    for _ in range(num_octaves - 1):\n","        octaves.append(nd.zoom(octaves[-1], (1, 1, 1 / octave_scale, 1 / octave_scale), order=1))\n","\n","    detail = np.zeros_like(octaves[-1])\n","    for octave, octave_base in enumerate(tqdm.tqdm(octaves[::-1], desc=\"Dreaming\")):\n","        if octave > 0:\n","            # Upsample detail to new octave dimension\n","            detail = nd.zoom(detail, np.array(octave_base.shape) / np.array(detail.shape), order=1)\n","        # Add deep dream detail from previous octave to new base\n","        input_image = octave_base + detail\n","        # Get new deep dream image\n","        dreamed_image = dream(input_image, model, iterations, lr)\n","        # Extract deep dream details\n","        detail = dreamed_image - octave_base\n","\n","    return deprocess(dreamed_image)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yoe-SDu52A3T","colab_type":"text"},"source":["# Let's get an image"]},{"cell_type":"code","metadata":{"id":"3CFxFkOZ2EcG","colab_type":"code","outputId":"ae62c2fc-f8ef-4c94-d831-4b56c04f4131","executionInfo":{"status":"ok","timestamp":1565182363237,"user_tz":-60,"elapsed":3951,"user":{"displayName":"James Ascroft","photoUrl":"https://lh3.googleusercontent.com/-JH9t_j6V1L8/AAAAAAAAAAI/AAAAAAAAAAc/8PcwXywM3Fs/s64/photo.jpg","userId":"16512234755285718867"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!mkdir images\n","!wget \"./images/img_0260.jpg\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2019-08-07 12:52:42--  http://./images/img_0260.jpg\n","Resolving . (.)... failed: No address associated with hostname.\n","wget: unable to resolve host address ‘.’\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GUD_j2Bc5izS","colab_type":"text"},"source":["# Some values before running the deep dream"]},{"cell_type":"code","metadata":{"id":"aMKrlcfV3mRf","colab_type":"code","colab":{}},"source":["input_image = \"./images/img_0260.jpg\"\n","at_layer = 27\n","lr = 0.01\n","octave_scale = 1.4\n","num_octaves = 10\n","iterations = 20"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sPsuM4-K5nml","colab_type":"text"},"source":["# Run deepdream"]},{"cell_type":"code","metadata":{"id":"A7VeQqxy3kib","colab_type":"code","outputId":"82bacad9-0035-43ad-8125-2bc0bbe889b8","executionInfo":{"status":"error","timestamp":1565182363389,"user_tz":-60,"elapsed":4093,"user":{"displayName":"James Ascroft","photoUrl":"https://lh3.googleusercontent.com/-JH9t_j6V1L8/AAAAAAAAAAI/AAAAAAAAAAc/8PcwXywM3Fs/s64/photo.jpg","userId":"16512234755285718867"}},"colab":{"base_uri":"https://localhost:8080/","height":351}},"source":["# Load image\n","    image = Image.open(input_image)\n","\n","    # Define the model\n","    network = models.vgg19(pretrained=True)\n","    layers = list(network.features.children())\n","    model = nn.Sequential(*layers[: (at_layer + 1)])\n","    if torch.cuda.is_available:\n","        model = model.cuda()\n","        \n","    print(network)\n","\n","    # Extract deep dream image\n","    dreamed_image = deep_dream(\n","        image,\n","        model,\n","        iterations=iterations,\n","        lr=lr,\n","        octave_scale=octave_scale,\n","        num_octaves=num_octaves,\n","    )\n","\n","    # Save and plot image\n","    os.makedirs(\"outputs\", exist_ok=True)\n","    filename = input_image.split(\"/\")[-1]\n","    plt.figure(figsize=(20, 20))\n","    plt.imshow(dreamed_image)\n","    plt.imsave(f\"outputs/output_{filename}\", dreamed_image)\n","    plt.show()"],"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7e8081c0925b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/img_0260.jpg'"]}]}]}