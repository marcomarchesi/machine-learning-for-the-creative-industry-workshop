{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"day4_pix2pix.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YrKtA_6d-Iwk","colab_type":"text"},"source":["Download the dataset\n","-------------------------\n","\n"]},{"cell_type":"code","metadata":{"id":"O1a-PvUg-xv0","colab_type":"code","outputId":"b684ab37-8e6c-40f1-9737-0db805e1fe47","executionInfo":{"status":"ok","timestamp":1564134147829,"user_tz":-60,"elapsed":17030,"user":{"displayName":"Angus Grant","photoUrl":"https://lh6.googleusercontent.com/-IxZpWRIhCo8/AAAAAAAAAAI/AAAAAAAAFLs/W5HcCre_52o/s64/photo.jpg","userId":"01966056732076356275"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["!wget \"http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\" -P \"./data\"\n","!tar -zxvf \"/content/data/facades.tar.gz\" -C \"/content/data/\" > \"/content/data/output.log\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-07-26 09:42:11--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n","Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n","Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30168306 (29M) [application/x-gzip]\n","Saving to: ‘./data/facades.tar.gz’\n","\n","facades.tar.gz      100%[===================>]  28.77M  2.11MB/s    in 14s     \n","\n","2019-07-26 09:42:25 (2.05 MB/s) - ‘./data/facades.tar.gz’ saved [30168306/30168306]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tjyoOrUdUfY_","colab_type":"text"},"source":["# Import PyTorch"]},{"cell_type":"code","metadata":{"id":"uiXaswJYrhBC","colab_type":"code","colab":{}},"source":["import torch\n","from torchvision import datasets, transforms\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import os\n","import numpy as np\n","from torchvision.utils import save_image"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6dS9KztrUiCf","colab_type":"text"},"source":["# Some values"]},{"cell_type":"code","metadata":{"id":"beNI-nRQw1df","colab_type":"code","colab":{}},"source":["batch_size = 32\n","learning_rate = 0.002\n","beta1 = 0.5\n","beta2 = 0.999\n","z_dim = 100\n","\n","cuda = True if torch.cuda.is_available else False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CxE3ZRDIVN4d","colab_type":"text"},"source":["# Let's organize the dataset"]},{"cell_type":"code","metadata":{"id":"VJvITcbCxBgN","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5),\n","                        (0.5, 0.5, 0.5))\n","])\n","\n","data_path = \"./data/facades\"\n","\n","def create_dataset(path, mode):\n","  dataset = datasets.ImageFolder(path, transform=transform)\n","  index = dataset.class_to_idx[mode]\n","  \n","  n = 0\n","  for i in range(dataset.__len__()):\n","    if dataset.imgs[n][1] != index:\n","      del dataset.imgs[n]\n","      n -= 1\n","    n += 1\n","  return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","                                    \n","\n","def make_dataset(path, index):\n","  dataset = datasets.ImageFolder(path, transform=transform)\n","#   index = dataset.class_to_idx[mode]\n","  \n","  n = 0\n","  for i in range(dataset.__len__()):\n","    if dataset.imgs[n][1] != index and dataset.imgs[n][1] != (index + 1):\n","      del dataset.imgs[n]\n","      n -= 1\n","    n += 1\n","  return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","train_data = create_dataset(data_path, \"train\")\n","test_data = create_dataset(data_path, \"test\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ialPb8S9VQiq","colab_type":"text"},"source":["# Design the model"]},{"cell_type":"code","metadata":{"id":"bNh2Akj4KuO6","colab_type":"code","colab":{}},"source":["import torch.nn.functional as F\n","\n","img_shape = (256, 256, 3)\n","\n","class Generator(nn.Module):\n","    # initializers\n","    def __init__(self, d=64):\n","        super(Generator, self).__init__()\n","        # Unet encoder\n","        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n","        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n","        self.conv2_bn = nn.BatchNorm2d(d * 2)\n","        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n","        self.conv3_bn = nn.BatchNorm2d(d * 4)\n","        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 2, 1)\n","        self.conv4_bn = nn.BatchNorm2d(d * 8)\n","        self.conv5 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n","        self.conv5_bn = nn.BatchNorm2d(d * 8)\n","        self.conv6 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n","        self.conv6_bn = nn.BatchNorm2d(d * 8)\n","        self.conv7 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n","        self.conv7_bn = nn.BatchNorm2d(d * 8)\n","        self.conv8 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n","        # self.conv8_bn = nn.BatchNorm2d(d * 8)\n","\n","        # Unet decoder\n","        self.deconv1 = nn.ConvTranspose2d(d * 8, d * 8, 4, 2, 1)\n","        self.deconv1_bn = nn.BatchNorm2d(d * 8)\n","        self.deconv2 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n","        self.deconv2_bn = nn.BatchNorm2d(d * 8)\n","        self.deconv3 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n","        self.deconv3_bn = nn.BatchNorm2d(d * 8)\n","        self.deconv4 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n","        self.deconv4_bn = nn.BatchNorm2d(d * 8)\n","        self.deconv5 = nn.ConvTranspose2d(d * 8 * 2, d * 4, 4, 2, 1)\n","        self.deconv5_bn = nn.BatchNorm2d(d * 4)\n","        self.deconv6 = nn.ConvTranspose2d(d * 4 * 2, d * 2, 4, 2, 1)\n","        self.deconv6_bn = nn.BatchNorm2d(d * 2)\n","        self.deconv7 = nn.ConvTranspose2d(d * 2 * 2, d, 4, 2, 1)\n","        self.deconv7_bn = nn.BatchNorm2d(d)\n","        self.deconv8 = nn.ConvTranspose2d(d * 2, 3, 4, 2, 1)\n","\n","    # weight_init\n","    def weight_init(self, mean, std):\n","        for m in self._modules:\n","            normal_init(self._modules[m], mean, std)\n","\n","    # forward method\n","    def forward(self, input):\n","        e1 = self.conv1(input)\n","        e2 = self.conv2_bn(self.conv2(F.leaky_relu(e1, 0.2)))\n","        e3 = self.conv3_bn(self.conv3(F.leaky_relu(e2, 0.2)))\n","        e4 = self.conv4_bn(self.conv4(F.leaky_relu(e3, 0.2)))\n","        e5 = self.conv5_bn(self.conv5(F.leaky_relu(e4, 0.2)))\n","        e6 = self.conv6_bn(self.conv6(F.leaky_relu(e5, 0.2)))\n","        e7 = self.conv7_bn(self.conv7(F.leaky_relu(e6, 0.2)))\n","        e8 = self.conv8(F.leaky_relu(e7, 0.2))\n","        # e8 = self.conv8_bn(self.conv8(F.leaky_relu(e7, 0.2)))\n","        d1 = F.dropout(self.deconv1_bn(self.deconv1(F.relu(e8))), 0.5, training=True)\n","        d1 = torch.cat([d1, e7], 1)\n","        d2 = F.dropout(self.deconv2_bn(self.deconv2(F.relu(d1))), 0.5, training=True)\n","        d2 = torch.cat([d2, e6], 1)\n","        d3 = F.dropout(self.deconv3_bn(self.deconv3(F.relu(d2))), 0.5, training=True)\n","        d3 = torch.cat([d3, e5], 1)\n","        d4 = self.deconv4_bn(self.deconv4(F.relu(d3)))\n","        # d4 = F.dropout(self.deconv4_bn(self.deconv4(F.relu(d3))), 0.5)\n","        d4 = torch.cat([d4, e4], 1)\n","        d5 = self.deconv5_bn(self.deconv5(F.relu(d4)))\n","        d5 = torch.cat([d5, e3], 1)\n","        d6 = self.deconv6_bn(self.deconv6(F.relu(d5)))\n","        d6 = torch.cat([d6, e2], 1)\n","        d7 = self.deconv7_bn(self.deconv7(F.relu(d6)))\n","        d7 = torch.cat([d7, e1], 1)\n","        d8 = self.deconv8(F.relu(d7))\n","        o = torch.tanh(d8)\n","\n","        return o\n","\n","class Discriminator(nn.Module):\n","    # initializers\n","    def __init__(self, d=64):\n","        super(Discriminator, self).__init__()\n","        self.conv1 = nn.Conv2d(6, d, 4, 2, 1)\n","        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n","        self.conv2_bn = nn.BatchNorm2d(d * 2)\n","        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n","        self.conv3_bn = nn.BatchNorm2d(d * 4)\n","        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 1, 1)\n","        self.conv4_bn = nn.BatchNorm2d(d * 8)\n","        self.conv5 = nn.Conv2d(d * 8, 1, 4, 1, 1)\n","\n","    # weight_init\n","    def weight_init(self, mean, std):\n","        for m in self._modules:\n","            normal_init(self._modules[m], mean, std)\n","\n","    # forward method\n","    def forward(self, input, label):\n","        x = torch.cat([input, label], 1)\n","        x = F.leaky_relu(self.conv1(x), 0.2)\n","        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n","        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n","        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n","        x = torch.sigmoid(self.conv5(x))\n","\n","        return x\n","\n","def normal_init(m, mean, std):\n","    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n","        m.weight.data.normal_(mean, std)\n","        m.bias.data.zero_()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2nFgOeI3ZTLP","colab_type":"text"},"source":["# Define loss and optimizers"]},{"cell_type":"code","metadata":{"id":"-C37JkGVLglp","colab_type":"code","colab":{}},"source":["G = Generator()\n","D = Discriminator()\n","bce_loss = nn.BCELoss()\n","l1_loss = nn.L1Loss()\n","\n","if cuda:\n","  G.cuda()\n","  D.cuda()\n","  bce_loss.cuda()\n","  l1_loss.cuda()\n","\n","g_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=(beta1, beta2))\n","d_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate, betas=(beta1, beta2))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X2N0YXxiZ_BA","colab_type":"text"},"source":["# Time to train!"]},{"cell_type":"code","metadata":{"id":"bDZnE7MRa9qc","colab_type":"code","outputId":"f2c601d5-cf2b-4227-deb2-9182ec72ea14","executionInfo":{"status":"ok","timestamp":1564060597399,"user_tz":-60,"elapsed":564199,"user":{"displayName":"grzesiek sedek","photoUrl":"","userId":"12860205744622623294"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["epochs = 200\n","\n","os.makedirs(\"./images\", exist_ok=True)\n","\n","for epoch in range(epochs):\n","  \n","  for i, (data, _) in enumerate(train_data):\n","    \n","    if cuda:\n","      data = Variable(data.cuda())\n","      \n","    _y = Variable(data[:, :, :, :256].cuda())\n","    _x = Variable(data[:, :, :, 256:].cuda())\n","    \n","    # Train the Discriminator\n","    D.zero_grad()\n","    \n","    D_result = D(_x, _y)\n","    \n","    real = Variable(torch.ones(D_result.size()).cuda(), requires_grad=False)\n","    fake = Variable(torch.zeros(D_result.size()).cuda(), requires_grad=False)\n","    \n","    real_loss = bce_loss(D_result, real)\n","    G_result = G(_x)\n","    D_result = D(_x, G_result)\n","    fake_loss = bce_loss(D_result, fake)\n","    \n","    d_loss = (real_loss + fake_loss) / 2\n","    d_loss.backward()\n","    d_optimizer.step()\n","    \n","    # Train the Generator\n","    G.zero_grad()\n","    \n","    G_result = G(_x)\n","    D_result = D(_x, G_result)\n","    \n","    g_loss = bce_loss(D_result, real) + 100 * l1_loss(G_result, _y) \n","    g_loss.backward()\n","    g_optimizer.step()\n","    \n","    \n","    batches_done = epoch * len(data) + i\n","    if batches_done % 10 == 0:\n","      print(\"Epoch %d, Batch %d\" % (epoch, i))\n","      save_image(G_result.data[:25], \"images/%d.png\" % batches_done, \n","                 nrow=5, \n","                 normalize=True)\n","    \n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 0, Batch 0\n","Epoch 0, Batch 10\n","Epoch 1, Batch 8\n","Epoch 2, Batch 6\n","Epoch 3, Batch 4\n","Epoch 3, Batch 12\n","Epoch 4, Batch 2\n","Epoch 5, Batch 0\n","Epoch 5, Batch 10\n","Epoch 6, Batch 8\n","Epoch 7, Batch 6\n","Epoch 8, Batch 4\n","Epoch 8, Batch 12\n","Epoch 9, Batch 2\n","Epoch 10, Batch 0\n","Epoch 10, Batch 10\n","Epoch 11, Batch 8\n","Epoch 12, Batch 6\n","Epoch 13, Batch 4\n","Epoch 13, Batch 12\n","Epoch 14, Batch 2\n","Epoch 15, Batch 0\n","Epoch 15, Batch 10\n","Epoch 16, Batch 8\n","Epoch 17, Batch 6\n","Epoch 18, Batch 4\n","Epoch 18, Batch 12\n","Epoch 19, Batch 2\n","Epoch 20, Batch 0\n","Epoch 20, Batch 10\n","Epoch 21, Batch 8\n","Epoch 22, Batch 6\n","Epoch 23, Batch 4\n","Epoch 23, Batch 12\n","Epoch 24, Batch 2\n","Epoch 25, Batch 0\n","Epoch 25, Batch 10\n","Epoch 26, Batch 8\n","Epoch 27, Batch 6\n","Epoch 28, Batch 4\n","Epoch 28, Batch 12\n","Epoch 29, Batch 2\n","Epoch 30, Batch 0\n","Epoch 30, Batch 10\n","Epoch 31, Batch 8\n","Epoch 32, Batch 6\n","Epoch 33, Batch 4\n","Epoch 33, Batch 12\n","Epoch 34, Batch 2\n","Epoch 35, Batch 0\n","Epoch 35, Batch 10\n","Epoch 36, Batch 8\n","Epoch 37, Batch 6\n","Epoch 38, Batch 4\n","Epoch 38, Batch 12\n","Epoch 39, Batch 2\n","Epoch 40, Batch 0\n","Epoch 40, Batch 10\n","Epoch 41, Batch 8\n","Epoch 42, Batch 6\n","Epoch 43, Batch 4\n","Epoch 43, Batch 12\n","Epoch 44, Batch 2\n","Epoch 45, Batch 0\n","Epoch 45, Batch 10\n","Epoch 46, Batch 8\n","Epoch 47, Batch 6\n","Epoch 48, Batch 4\n","Epoch 48, Batch 12\n"],"name":"stdout"}]}]}